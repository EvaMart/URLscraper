<-- http://www.popgen.dk/angsd/index.php/Input-->

ANGSD: Analysis of next generation Sequencing Data
Latest tar.gz version is (0.930/0.931 on github), see Change_log for changes, and download it  here.
Jump to: navigation, search
ANGSD currently supports various input formats
Below is a short description of those we believe is of most use. Note that CRAM files are used interchangeably as BAM files. So use -bam for supplying both a CRAM list or BAM list or both.
* 1 Sequence data (BAM/CRAM/mpileup)
* 1.2 Pileup files
* 2 BCF/VCF files
* 3 Genotype Likelihood Files
* 4 Genotype Probability Files
* 4.1 Beagle format
# Sequence data (BAM/CRAM/mpileup)
ANGSD accepts BAM/CRAM files for mapped sequences and both are handled using the same -bam option. For information on the file specification and file creation see the samtools website [1]. These are required do be sorted according to reference. To see the options for BAM/CRAM use the command:
-> angsd version: 0.910-14-g5e2711f (htslib: 1.2.1-252-ga2656aa) build(Dec  4 2015 10:40:24)
-> Analysis helpbox/synopsis information:
-> angsd version: 0.910-14-g5e2711f (htslib: 1.2.1-252-ga2656aa) build(Dec  4 2015 10:40:28)
-> Fri Dec  4 10:43:27 2015
-r		(null)	Supply a single region in commandline (see examples below)
-rf		(null)	Supply multiple regions in a file (see examples below)
-remove_bads	1	Discard 'bad' reads, (flag >=256) 
-uniqueOnly	0	Discards reads that doesn't map uniquely
-show		0	Mimic 'samtools mpileup' also supply -ref fasta for printing reference column
-minMapQ	0	Discard reads with mapping quality below
-minQ		13	Discard bases with base quality below
-trim		0	Number of based to discard at both ends of the reads
-only_proper_pairs	1	Only use reads where the mate could be mapped
-C		0	adjust mapQ for excessive mismatches (as SAMtools), supply -ref
-baq		0	adjust qscores around indels (as SAMtools), supply -ref
-if		2	include flags for each read
-df		4	discard flags for each read
-checkBamHeaders	1	Exit if difference in BAM headers
-doCheck	1	Keep going even if datafile is not suffixed with .bam/.cram
-downSample	0.000000	Downsample to the fraction of original data
-minChunkSize	250	Minimum size of chunk sent to analyses
Examples for region specification:
chr:		Use entire chromosome: chr
chr:start-	Use region from start to end of chr
chr:-stop	Use region from beginning of chromosome: chr to stop
chr:start-stop	Use region from start to stop from chromosome: chr
chr:site	Use single site on chromosome: chr
Will include read if:
includeflag:[2] (beta)each segment properly aligned according to the aligner, 
Will discard read if:
discardflag:[4] (beta)segment unmapped, 
Example of estimating allele frequencies from bam files
./angsd -out out -doMaf 2 -bam bam.filelist -doMajorMinor 1 -GL 1 -P 5
-bam [filelist] -b [filelist]
The filelist is a file containing the full path for each bam file with one filename per row.
filelist with 6 individuals
Specify a region with in a chromosome using the syntax [chr]:[start-stop]. examples
chr1:1-10000             \\ first 10000 based for chr1
chr2:50000-              \\chr2 but exclude the first 50000 bases
chr11:1-                 \\all of chr11
chr11:                   \\all of chr11
chr7:123456              \\position 123456 of chr7
-rf [region file] 
Specify multiple regions in a file using the same syntax as -r
Same as the samtools flags -x which removes read with a flag above 255 (not primary, failure and duplicate reads). 0 no , 1 remove (default).
Remove reads that have multiple best hits. 0 no (default), 1 remove.
Number of bases to remove from both ends of the read.
Include only proper pairs (pairs of read with both mates mapped correctly). 1: include only proper (default), 0: use all reads. Only relevant for paired end data.
Adjust mapQ for excessive mismatches (as SAMtools), supply -ref.
Perform BAQ computation, remember to cite the| BAQ paper for this. 0: No BAQ calcualtion
1:normal BAQ (same as default in SAMtools). 2:extended BAQ (same as default in SAMtools).
if zero then it will use the existing record
You will need to supply your reference (-ref) for BAQ options.
Exits if the headers are not compatible for all files. 0 no , 1 remove (default). Not performing this check is not advisable
Randomly remove reads to downsample your data. 0.25 will on average keep 25% of the reads
Minimum number of sites to read in before starting to analyze - larger number will use more RAM
Pileup files are the output files that are generated by SAMtools mpileup.
-> angsd version: 0.910-20-g553b991 (htslib: 1.2.1-192-ge7e2b3d) build(Dec  4 2015 12:17:14)
-> Analysis helpbox/synopsis information:
../angsd/angsd -pileup 	-> Fri Dec  4 12:17:53 2015
-nLines	50	(Number of lines to read)
-beagle	(null)	(Beagle Filename (can be .gz))
-vcf-GL	(null)	(vcf Filename (can be .gz))
-vcf-GP	(null)	(vcf Filename (can be .gz))
-glf	(null)	(glf Filename (can be .gz))
-pileup	(null)	(pileup Filename (can be .gz))
-intName 1	(Assume First column is chr_position)
-isSim	0	(Simulated data assumes ancestral is A)
-minQ	13	(minimum base quality; only used in pileupreader)
./angsd -pileup sam.mpileup -nInd 10 -fai hg19.fa.gz.fai
name of the pileup file.
Number of individuals must be specified.
The index to the reference genome.
maximum bytes per line. Increase if the pileup has many individuals.
Number of lines to read at a time. Increasing this number will affect the RAM use.
Minimum base quality score.
Various softwares can generate pileup format but the most used one is samtools
samtools mpileup -b bam.filelist > sam.mpileup
if you can then use it as input to angsd
./angsd -pileup sam.mpileup -nInd 10 -fai hg19.fa.gz.fai -domaf 1 -domajorminor 1 -gl 1
BCF/VCF file as input is now included but with some limitations. Only chr,pos and PL tags are being used, and we discard indels.
-> angsd version: 0.910-20-g553b991 (htslib: 1.2.1-192-ge7e2b3d) build(Dec  4 2015 12:17:14)
-> Analysis helpbox/synopsis information:
./angsd -vcf-gl 	-> Fri Dec  4 14:35:51 2015
-nLines	50	(Number of lines to read)
-beagle	(null)	(Beagle Filename (can be .gz))
-vcf-GL	(null)	(vcf Filename (can be .gz))
-vcf-GP	(null)	(vcf Filename (can be .gz))
-glf	(null)	(glf Filename (can be .gz))
-pileup	(null)	(pileup Filename (can be .gz))
-intName 1	(Assume First column is chr_position)
-isSim	0	(Simulated data assumes ancestral is A)
-minQ	13	(minimum base quality; only used in pileupreader)
angsd -vcf-gl ../smallBam/small2.bcf -domajorminor 1 -domaf 1
name of the vcf file.
##FORMAT=<ID=GL,Number=G,Type=Float,Description="scaled Genotype Likelihoods (loglikeratios to the most likely (in log10))">
Number of lines to read at a time. Increasing this number will affect the RAM use.
Create a VCF file using your favorate software or using angsd
./angsd -b bam.filelist -dovcf 1 -gl 1 -dopost 1 -domajorminor 1 -domaf 1 -snp_pval 1e-6
you can then use it as input to angsd if you have the GL info
./angsd -vcf-gl angsdput.vcf.gz -nind 10 -fai hg19.fa.gz.fai -domaf 1
# Genotype Likelihood Files
A simple format for genotype likelihoods: This is the format used by _supersim_ subprogram and the _-doglf 1_ option in angsd. This format is binary, 10doubles per individual. -nInd therefore needs to be supplied
-> angsd version: 0.910-20-g553b991 (htslib: 1.2.1-192-ge7e2b3d) build(Dec  4 2015 12:17:14)
-> Analysis helpbox/synopsis information:
../angsd/angsd -pileup 	-> Fri Dec  4 12:17:53 2015
-nLines	50	(Number of lines to read)
-beagle	(null)	(Beagle Filename (can be .gz))
-vcf-GL	(null)	(vcf Filename (can be .gz))
-vcf-GP	(null)	(vcf Filename (can be .gz))
-glf	(null)	(glf Filename (can be .gz))
-pileup	(null)	(pileup Filename (can be .gz))
-intName 1	(Assume First column is chr_position)
-isSim	0	(Simulated data assumes ancestral is A)
-minQ	13	(minimum base quality; only used in pileupreader)
./angsd -glf data.glf.gz -nInd 10 -fai hg19.fa.gz.fai
name of the glf file (gunzipped). Every genotype likelihood is saved as binary double log scaled. In the following order. AA,AC,AG,AT,... for each individual
Number of individuals must be specified.
The index to the reference genome.
maximum bytes per line. Increase if the pileup has many individuals.
Number of lines to read at a time. Increasing this number will affect the RAM use.
Minimum base quality score.
supersim -outfiles data -nind 10 -nsites 100000 -errate 0.01 -depth 4
then use it as input to angsd
./angsd -glf data.glf.gz -nInd 10 -fai hg19.fa.gz.fai -domaf 1 -domajorminor 1
make GLF file from the chromosome 1
./angsd -GL 1 -out genolike -doGlf 1 -doMajorMinor 1  -doMaf 2 -SNP_pval 2e-6 -bam bam.filelist -r 1:
recalculate the allele frequencies
./angsd -glf genolike.glf.gz -nInd 10 -fai hg19.fa.gz.fai -domaf 2 -domajorminor 1
-glf10_text was added in commit: https://github.com/ANGSD/angsd/commit/46fc3edc181e80c4ad5e6bd644a64d23a5012e0e nov2 2017. This allows for reading files in the output format as -doglf 4. This is a simple text file with column 1 and column 2 being chromosome/scaffold and position. Then for each individual there are 10 logscaled genotype likelihoods in the order: AA,AC,AG,AT,CC,CG,CT,GG,GT,TT. Example runs are: First generate an example of this format: 
./angsd -gl 1 -doglf 4 -bam list -out first -domajorminor 1 -domaf 1
This generates the file first.glf.gz. Which we can then use as input. Example here:
./angsd -glf10_text first.glf.gz -nind 33 -domaf 1 -domajorminor 1 -fai fai.fai 
Notice that -nInd and -fai needs to be supplied.
# Genotype Probability Files
Genotype probabilities in gz beagle format can be used as input. The format used is the haplotype imputation format outputted from beagle [2]. A newer version of beagle uses VCF files.
-> angsd version: 0.910-20-g553b991 (htslib: 1.2.1-192-ge7e2b3d) build(Dec  4 2015 12:17:14)
-> Analysis helpbox/synopsis information:
./angsd -beagle 	-> Fri Dec  4 14:03:22 2015
-nLines	50	(Number of lines to read)
-beagle	(null)	(Beagle Filename (can be .gz))
-vcf-GL	(null)	(vcf Filename (can be .gz))
-vcf-GP	(null)	(vcf Filename (can be .gz))
-glf	(null)	(glf Filename (can be .gz))
-pileup	(null)	(pileup Filename (can be .gz))
-intName 1	(Assume First column is chr_position)
-isSim	0	(Simulated data assumes ancestral is A)
-minQ	13	(minimum base quality; only used in pileupreader)
Example of estimating allele frequencies from beagle files
./angsd -out out -doMaf 4 -beagle file.beagle.gprobs.gz -fai ref.fai
beagle file name. The file must be gzipped. The file format is a single line per site. The first 3 coloums are
For each individual 3 columns are added. These three columns should sum to one.
file with two individuals
marker alleleA alleleB NA06984 NA06984 NA06984 NA06986 NA06986 NA06986
chr9_95759065 G A 0.6563 0.3078 0.0358 0.5357 0.4016 0.0627
chr9_95759152 C A 1 0 0 0 1 0
chr9_95762332 G A 0.925 0.0734 0.0015 0.894 0.1031 0.0029
chr9_95762333 A T 0.8903 0.1067 0.003 0.811 0.1797 0.0093
chr9_95762343 G T 0.9149 0.0835 0.0017 0.8396 0.1541 0.0064
default 1. If the SNP name are written as chr_position this information will be parsed. If the SNP name is in another format then use -intName 0.
The index to the reference genome
can also be obtained from the bam header
samtools view -H  file.bam | grep SN |cut -f2,3 | sed 's/SN\://g' |  sed 's/LN\://g' > ref.fai
maximum bytes per line. Increase if the pileup has many individuals
Number of lines to read at a time. Increasing this number will affect the RAM use
* (Multi) SFS Estimation
* Population branch statistics (pbs)
* PCA (sampling approach)
* HWE and inbreeding with ngsF
* Create Fasta file
### SNPs and genotypes
* Major and Minor
* Genotype likelihood files
* overview of class
* accessing core data
* custom data containers
* What links here
* This page was last modified on 22 February 2019, at 18:28.